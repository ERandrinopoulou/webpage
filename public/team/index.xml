<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Teams on ER Andrinopoulou</title>
    <link>https://www.erandrinopoulou.com/team/</link>
    <description>Recent content in Teams on ER Andrinopoulou</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 01 Feb 2020 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://www.erandrinopoulou.com/team/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Aglina Lika</title>
      <link>https://www.erandrinopoulou.com/team/aglina/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.erandrinopoulou.com/team/aglina/</guid>
      <description>&lt;p&gt;Aglina Lika is a PhD student working on the following projects:&lt;/p&gt;
&lt;h2 id=&#34;the-effects-of-parametrizations-and-scaling-on-generalized-linear-mixed-models-using-hamiltonian-monte-carlo-algorithm&#34;&gt;The effects of Parametrizations and Scaling on Generalized Linear Mixed Models using Hamiltonian Monte Carlo algorithm&lt;/h2&gt;
&lt;p&gt;Fitting generalized linear mixed models under the Bayesian approach can be computationally expensive. Such situations typically appear in applications where non-linear, high-dimensional parameter space, and/or complicated covariance structures exist. This gives rise to study efficient model parameterizations and data normalization that improve the convergence. In this paper, we compared the convergence time complexity of Hamiltonian Monte Carlo (HMC) techniques with scaled data using centered and non-centered parametrizations through a simulation study.&lt;/p&gt;
&lt;h2 id=&#34;bayesian-approach-for-multivariate-longitudinal-data-analysis-assuming-different-association-structures&#34;&gt;Bayesian approach for multivariate longitudinal data analysis assuming different association structures&lt;/h2&gt;
&lt;p&gt;Studies in life course epidemiology often involve different types of outcomes being collected on individuals, who are followed over time. These outcomes are mainly analysed separately, although it may be of scientific interest to study their associations. To model the correlation of multiple longitudinal outcomes, it is common to assume a multivariate normal distribution for the corresponding random effects. This approach, however, has its limitations in terms of interpreting the strength of association between the outcomes. To overcome this, we can include several longitudinal outcomes, as time-dependent covariates, in the model of the main longitudinal outcome. Another advantage is that several features of these longitudinal predictors could be used, namely the previous values, the slope and the area under the curve. The proposed multivariate mixed model can incorporate different functional forms to link multiple outcomes assuming the Bayesian framework. Applications are illustrated on a dataset from a study on Pompe disease, where it is important to investigate how physical outcomes and patient-reported outcomes are associated.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pedro Afonso</title>
      <link>https://www.erandrinopoulou.com/team/pedro/</link>
      <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.erandrinopoulou.com/team/pedro/</guid>
      <description>&lt;p&gt;Pedro Afonso is a PhD student working on the following projects:&lt;/p&gt;
&lt;h2 id=&#34;efficiently-analyzing-big-data-with-bayesian-joint-models-for-longitudinal-and-time-to-event-data&#34;&gt;Efficiently analyzing big data with Bayesian joint models for longitudinal and time-to-event data&lt;/h2&gt;
&lt;p&gt;The joint modeling of longitudinal and time-to-event outcomes has become a popular tool in follow-up stud-
ies. However, fitting Bayesian joint models to large datasets, such as patient registries, can require extended
computing times. To speed up sampling, we divided a patient registry dataset into subsamples, analyzed
them in parallel, and combined the resulting Markov chain Monte Carlo draws into a consensus distribu-
tion. We used a simulation study to investigate how different consensus strategies perform with joint models.
In particular, we compared grouping all draws together with using equal- and precision-weighted averages.
We considered scenarios reflecting different sample sizes, numbers of data splits, and processor characteris-
tics. Parallelization of the sampling process substantially decreased the time required to run the model. We
found that the weighted-average consensus distributions for large sample sizes were nearly identical to the
target posterior distribution. The proposed algorithm has been made available in an R package for joint mod-
els, JMbayes2. This work was motivated by the clinical interest in investigating the association between
ppFEV1, a commonly measured marker of lung function, and the risk of lung transplant or death, using data
from the US Cystic Fibrosis Foundation Patient Registry (35,153 individuals with 372,366 years of cumu-
lative follow-up). Splitting the registry into five subsamples resulted in an 85% decrease in computing time,
from 9.22 to 1.39 hours. Splitting the data and finding a consensus distribution by precision-weighted aver-
aging proved to be a computationally efficient and robust approach to handling large datasets under the joint
modeling framework.&lt;/p&gt;
&lt;h2 id=&#34;between--and-within-group-comparisons-of-fev1-rate-of-decline-in-cystic-fibrosis&#34;&gt;Between- and Within-Group Comparisons of FEV1 Rate of Decline in Cystic Fibrosis&lt;/h2&gt;
&lt;p&gt;Difference in rate of change for before and after Ivacaftor treatment in subjects with a G551D mutation. Different modelling approaches (linear mixed-effects models, generalized estimating equations and joint models of longitudinal and survival data) and data scenarios are investigated.&lt;/p&gt;
&lt;h2 id=&#34;a-joint-model-for-unbounded-longitudinal-markers-competing-risks-and-recurrent-eventsa-joint-model-for-unbounded-longitudinal-markers-competing-risks-and-recurrent-events&#34;&gt;A joint model for (un)bounded longitudinal markers, competing risks, and recurrent events]{A joint model for (un)bounded longitudinal markers, competing risks, and recurrent events&lt;/h2&gt;
&lt;p&gt;Joint models for longitudinal and survival data have become a popular framework for studying the
association between repeatedly measured biomarkers and clinical events. Nevertheless, addressing complex survival
data structures, especially handling both recurrent and competing event times within a single model, remains a
challenge. This causes important information to be disregarded. Moreover, existing frameworks rely on a Gaussian
distribution for continuous markers, which may be unsuitable for bounded biomarkers, resulting in biased estimates of
associations. To address these limitations, we propose a Bayesian shared-parameter joint model that simultaneously
accommodates multiple (possibly bounded) longitudinal markers, a recurrent event process, and competing risks. We
use the beta distribution to model responses bounded within any interval (a, b) without sacrificing the interpretability
of the association. The model offers various forms of association, discontinuous risk intervals, and both gap and
calendar timescales. A simulation study shows that it outperforms simpler joint models. We analyze the US Cystic
Fibrosis Foundation Patient Registry to study the associations between lung function decline, cumulative changes
in body mass index, and the risk of recurrent pulmonary exacerbations, while accounting for the competing risks of
death and lung transplantation. Our efficient implementation allows fast fitting of the model despite its complexity
and the large sample size. Our comprehensive approach provides new insights into cystic fibrosis progression. The
model is available in the R package JMbayes2.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pedro Afonso</title>
      <link>https://www.erandrinopoulou.com/team/xu/</link>
      <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.erandrinopoulou.com/team/xu/</guid>
      <description>&lt;p&gt;Xu Wang is a former PhD student working on the following project:&lt;/p&gt;
&lt;h2 id=&#34;statistical-primer-an-introduction-to-the-application-of-linear-mixed-effects-models-in-cardiothoracic-surgery-outcomes-research-a-case-study-using-homograft-pulmonary-valve-replacement-data&#34;&gt;Statistical primer: an introduction to the application of linear mixed-effects models in cardiothoracic surgery outcomes research-a case study using homograft pulmonary valve replacement data&lt;/h2&gt;
&lt;p&gt;Objectives: The emergence of big cardio-thoracic surgery datasets that include not only short-term and long-term discrete outcomes but also repeated measurements over time offers the opportunity to apply more advanced modelling of outcomes. This article presents a detailed introduction to developing and interpreting linear mixed-effects models for repeated measurements in the setting of cardiothoracic surgery outcomes research.&lt;/p&gt;
&lt;p&gt;Methods: A retrospective dataset containing serial echocardiographic measurements in patients undergoing surgical pulmonary valve replacement from 1986 to 2017 in Erasmus MC was used to illustrate the steps of developing a linear mixed-effects model for clinician researchers.&lt;/p&gt;
&lt;p&gt;Results: Essential aspects of constructing the model are illustrated with the dataset including theories of linear mixed-effects models, missing values, collinearity, interaction, nonlinearity, model specification, results interpretation and assumptions evaluation. A comparison between linear regression models and linear mixed-effects models is done to elaborate on the strengths of linear mixed-effects models. An R script is provided for the implementation of the linear mixed-effects model.&lt;/p&gt;
&lt;p&gt;Conclusions: Linear mixed-effects models can provide evolutional details of repeated measurements and give more valid estimates compared to linear regression models in the setting of cardio-thoracic surgery outcomes research.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
